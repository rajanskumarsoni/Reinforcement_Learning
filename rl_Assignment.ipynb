{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl_Assignment",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm40EzWXwoAQ",
        "colab_type": "text"
      },
      "source": [
        "Algo used: 1 for epsilon greedy, 2 for softmax, 3 for UCB1 and 4 Median Elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUFOXHmPAfQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "\n",
        "np.random.seed(0)\n",
        "##### Generating means for all arms from Guassian distribution(0,1)\n",
        "def generate_mean_for_arms(mean, variance, number_of_arms):\n",
        "    return np.random.normal(mean,np.sqrt(variance),(number_of_arms))\n",
        "\n",
        "#########Implementation of epsilon greedy algo\n",
        "def generate_epsilon_greedy_run(number_of_steps,number_of_arms, epsilon, epsilon_decrease_allow ):\n",
        "    #Actual mean of arms \n",
        "    mean_for_arms = generate_mean_for_arms(0, 1, number_of_arms)\n",
        "    #Actual optimal action\n",
        "    optimal_action = np.argmax(mean_for_arms)\n",
        "    #Running expectead mean of arms\n",
        "    expected_mean_for_arms = np.zeros((number_of_arms))*1.0\n",
        "    #Counting the number of times an arm is selected\n",
        "    number_of_times_arm_selected = np.zeros((number_of_arms))\n",
        "    #Keeping the record wether Actual optimal action is chosen at time step t or not\n",
        "    optimal_action_chosen_at_step = np.zeros((number_of_steps))\n",
        "    #Keeping the reward at each time step\n",
        "    run = []\n",
        "    for i in range(number_of_steps):\n",
        "        if epsilon_decrease_allow == 1:\n",
        "            if i%10 == 0:\n",
        "                epsilon = epsilon - .99900e-4\n",
        "        r = np.random.uniform(0,1)\n",
        "        if r<epsilon:\n",
        "            action_chosen = np.random.randint(0,number_of_arms)\n",
        "            if action_chosen == optimal_action:\n",
        "                optimal_action_chosen_at_step[i] = optimal_action_chosen_at_step[i]+1\n",
        "            reward = np.random.normal(mean_for_arms[action_chosen],1)\n",
        "            run.append(reward)\n",
        "            \n",
        "            number_of_times_arm_selected[action_chosen]= number_of_times_arm_selected[action_chosen] +1\n",
        "            expected_mean_for_arms[action_chosen] = expected_mean_for_arms[action_chosen] + (reward - expected_mean_for_arms[action_chosen])/number_of_times_arm_selected[action_chosen]\n",
        "            # run.append(expected_mean_for_arms[action_chosen])\n",
        "        else:\n",
        "            action_chosen = np.argmax(expected_mean_for_arms)\n",
        "            if action_chosen == optimal_action:\n",
        "                optimal_action_chosen_at_step[i] = optimal_action_chosen_at_step[i]+1\n",
        "            \n",
        "            reward = np.random.normal(mean_for_arms[action_chosen],1)\n",
        "            run.append(reward)\n",
        "            \n",
        "            number_of_times_arm_selected[action_chosen]= number_of_times_arm_selected[action_chosen] +1\n",
        "            expected_mean_for_arms[action_chosen] = expected_mean_for_arms[action_chosen] + (reward - expected_mean_for_arms[action_chosen])/number_of_times_arm_selected[action_chosen]\n",
        "            # run.append(expected_mean_for_arms[action_chosen])\n",
        "        \n",
        "    return run, np.argmax(mean_for_arms), np.argmax(expected_mean_for_arms), number_of_times_arm_selected, optimal_action_chosen_at_step\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_softamx_run(number_of_steps,number_of_arms, temperature):\n",
        "    \n",
        "    mean_for_arms = generate_mean_for_arms(0, 1, number_of_arms)\n",
        "    optimal_action = np.argmax(mean_for_arms)\n",
        "    expected_mean_for_arms = np.zeros((number_of_arms))*1.0\n",
        "    number_of_times_arm_selected = np.zeros((number_of_arms))\n",
        "    optimal_action_chosen_at_step = np.zeros((number_of_steps))\n",
        "    run = []\n",
        "    for i in range(number_of_steps):\n",
        "        \n",
        "        softprob = softmax(expected_mean_for_arms/temperature)\n",
        "        \n",
        "        action_chosen = np.random.choice(np.arange(number_of_arms),p = softprob)\n",
        "        # print(\"action_chosen\", action_chosen)\n",
        "        if action_chosen == optimal_action:\n",
        "            optimal_action_chosen_at_step[i] = optimal_action_chosen_at_step[i]+1\n",
        "        reward = np.random.normal(mean_for_arms[action_chosen],1)\n",
        "        run.append(reward)\n",
        "        \n",
        "        number_of_times_arm_selected[action_chosen]= number_of_times_arm_selected[action_chosen] +1\n",
        "        expected_mean_for_arms[action_chosen] = expected_mean_for_arms[action_chosen] + (reward - expected_mean_for_arms[action_chosen])/number_of_times_arm_selected[action_chosen]\n",
        "            # run.append(expected_mean_for_arms[action_chosen])\n",
        "      \n",
        "        \n",
        "    return run, np.argmax(mean_for_arms), np.argmax(expected_mean_for_arms), number_of_times_arm_selected, optimal_action_chosen_at_step\n",
        "\n",
        "\n",
        "def generate_UCB_run(number_of_steps, number_of_arms, c):\n",
        "    \n",
        "    mean_for_arms = generate_mean_for_arms(0, 1, number_of_arms)\n",
        "    optimal_action = np.argmax(mean_for_arms)\n",
        "    expected_mean_for_arms = np.zeros((number_of_arms))*1.0\n",
        "    number_of_times_arm_selected = np.ones((number_of_arms))\n",
        "    optimal_action_chosen_at_step = np.zeros((number_of_steps))\n",
        "    run = []\n",
        "    for i in range(number_of_steps):\n",
        "    \n",
        "        # number_of_arms = 10\n",
        "        a= np.repeat(np.log(i+1),number_of_arms)\n",
        "        b = number_of_times_arm_selected\n",
        "        d = c*np.sqrt(a/b) + expected_mean_for_arms\n",
        "        action_chosen = np.argmax(d)\n",
        "        if action_chosen == optimal_action:\n",
        "            optimal_action_chosen_at_step[i] = optimal_action_chosen_at_step[i]+1\n",
        "        reward = np.random.normal(mean_for_arms[action_chosen],1)\n",
        "        run.append(reward)\n",
        "        \n",
        "        number_of_times_arm_selected[action_chosen]= number_of_times_arm_selected[action_chosen] +1\n",
        "        expected_mean_for_arms[action_chosen] = expected_mean_for_arms[action_chosen] + (reward - expected_mean_for_arms[action_chosen])/number_of_times_arm_selected[action_chosen]\n",
        "            \n",
        "        \n",
        "    return run, np.argmax(mean_for_arms), np.argmax(expected_mean_for_arms), number_of_times_arm_selected, optimal_action_chosen_at_step\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "def generate_median_elimination(number_of_arms,epsilon, delta):\n",
        "    mean_for_arms = generate_mean_for_arms(0, 1, number_of_arms)\n",
        "    optimal_action = np.argmax(mean_for_arms)\n",
        "    expected_mean_for_arms = np.zeros((number_of_arms))*1.0\n",
        "    epsilon_1 = epsilon/4\n",
        "    \n",
        "    times_to_pull_list_last = 0\n",
        "    delta_1 = delta/2\n",
        "    armlist = np.arange(number_of_arms)\n",
        "    total_count_samples = 0\n",
        "    is_optimal_action_retained = 0\n",
        "    time_for_sort = 0\n",
        "    optimal_action_chosen_at_step = []\n",
        "    run =[]\n",
        "    w = datetime.now()\n",
        "    while(len(armlist)>1):\n",
        "        samply = []\n",
        "        steps = []\n",
        "        times_to_pull = int(1/((epsilon_1/2)**2)*np.log10(3/delta_1))\n",
        "        total_count_samples = total_count_samples + times_to_pull*len(armlist)\n",
        "        for a in armlist:\n",
        "            samples = np.random.normal(mean_for_arms[a],1,(times_to_pull))\n",
        "            \n",
        "            samply = np.concatenate((samply,samples))\n",
        "            if int(a) == optimal_action:\n",
        "                \n",
        "                steps = np.concatenate((steps, np.ones(len(samples))))\n",
        "            else:\n",
        "                steps = np.concatenate((steps, np.zeros(len(samples))))\n",
        "            sums = np.sum(samples)\n",
        "            \n",
        "            expected_mean_for_arms[a]  = (expected_mean_for_arms[a]*times_to_pull_list_last +  sums)/(times_to_pull_list_last +times_to_pull )\n",
        "        np.random.shuffle(samply)\n",
        "        np.random.shuffle(steps)\n",
        "        optimal_action_chosen_at_step = np.concatenate((optimal_action_chosen_at_step, steps))\n",
        "        run = np.concatenate((run,samply))\n",
        "        # print(\"run\",np.array(run).shape)\n",
        "        times_to_pull_list_last = times_to_pull_list_last + times_to_pull\n",
        "        arr = np.array(expected_mean_for_arms)\n",
        "        \n",
        "        c = datetime.now()\n",
        "        q = arr.argsort()[-int(np.ceil(len(armlist)/2)):][::-1]\n",
        "        d = datetime.now()\n",
        "        time_for_sort = time_for_sort + (d-c).total_seconds()\n",
        "        armlist = q\n",
        "        # print(\"armlist\",armlist)\n",
        "        epsilon_1 = epsilon_1*(3/4)\n",
        "        delta_1 = delta_1/2\n",
        "        # print(\"loop end\")\n",
        "    if optimal_action == int(armlist[0]):\n",
        "       is_optimal_action_retained = 1 \n",
        "    b = datetime.now()\n",
        "    # print(\"time for algo, time for sort, time for other then algo\",(b-w).total_seconds(),time_for_sort, (b-w).total_seconds()-time_for_sort )\n",
        "    return optimal_action, armlist[0], total_count_samples, is_optimal_action_retained, run, optimal_action_chosen_at_step\n",
        "\n",
        "\n",
        "\n",
        "################Generating Average run over given number of Bandit problems\n",
        "def generate_average_run(number_of_bandits, number_of_steps,number_of_arms,algo_used,epsilon = 0,alpha = .1, temperature = 100, c = 1, epsilon_decrease_allow = 0,delta = .1):\n",
        "    \n",
        "        all_run = []\n",
        "        run = []\n",
        "        all_percent_optimal_action_chosen = []\n",
        "        optimal_action_chosen_at_step = []\n",
        "        optimal_action_retained_count = 0\n",
        "        total_count_samples = 0\n",
        "        for i in range(number_of_bandits):\n",
        "        \n",
        "            if algo_used == 1:\n",
        "                run, actual_best_arm,expected_best_arm, number_of_times_arm_selected, optimal_action_chosen_at_step = generate_epsilon_greedy_run(number_of_steps, number_of_arms,epsilon, epsilon_decrease_allow)\n",
        "            elif algo_used == 2:\n",
        "                run, actual_best_arm,expected_best_arm, number_of_times_arm_selected, optimal_action_chosen_at_step = generate_softamx_run(number_of_steps,number_of_arms,temperature)\n",
        "            elif algo_used == 3:\n",
        "                run, actual_best_arm,expected_best_arm, number_of_times_arm_selected, optimal_action_chosen_at_step  = generate_UCB_run(number_of_steps, number_of_arms, c)\n",
        "            elif algo_used == 4:\n",
        "                optimal_action, arm, total_count_samples, is_optimal_action_retained, run, optimal_action_chosen_at_step = generate_median_elimination(number_of_arms,epsilon, delta)\n",
        "                optimal_action_retained_count = optimal_action_retained_count + is_optimal_action_retained\n",
        "                # print(\"jhvjh\", np.array(run).shape)\n",
        "\n",
        "            # print(\"yo\",actual_best_arm,expected_best_arm, number_of_times_arm_selected)\n",
        "            all_run.append(run)\n",
        "            all_percent_optimal_action_chosen.append(optimal_action_chosen_at_step)\n",
        "        # print(\"ewd\",np.array(all_percent_optimal_action_chosen).shape)\n",
        "        return np.mean(all_run,0), (np.sum(all_percent_optimal_action_chosen,0)/number_of_bandits)*100, total_count_samples, (optimal_action_retained_count/number_of_bandits)*100\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fmqkNnXmzAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################Plot for question 1\n",
        "\n",
        "def plot1(number_of_bandits,number_of_steps,number_of_arms):\n",
        "    x = np.arange(number_of_steps)\n",
        "    y1, z1,_, _ = generate_average_run(number_of_bandits,number_of_steps, number_of_arms,1,0)\n",
        "    y2, z2, _,_ = generate_average_run(number_of_bandits,number_of_steps,number_of_arms,1,.1)\n",
        "    y3, z3,_,_ = generate_average_run(number_of_bandits,number_of_steps,number_of_arms,1,.01)\n",
        "    y4, z4,_,_ = generate_average_run(number_of_bandits,number_of_steps,number_of_arms,1,.1,epsilon_decrease_allow=1)\n",
        "    \n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.title(\"Average performance of epsilon-greedy action-value methods on the 1000-armed testbed\", fontsize=20)\n",
        "    plt.ylabel(\"Average reward\", fontsize=20)\n",
        "    plt.xlabel(\"Steps\", fontsize=20)\n",
        "    l1,=  plt.plot(x,y1, label = \"$\\epsilon$ 0\")\n",
        "    l2, =  plt.plot(x,y2, label = \"$\\epsilon$ 0.1\")\n",
        "    l3, =  plt.plot(x,y3, label = \"$\\epsilon$ 0.01\")\n",
        "    l4, =  plt.plot(x,y4, label = \"$\\epsilon$ 0.1 -.0001 \")\n",
        "    \n",
        "    plt.legend(handles=[l1,l2,l3,l4], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.ylabel(\"% Optimal action\",fontsize=20)\n",
        "    plt.xlabel(\"Steps\", fontsize=20)\n",
        "    l1, =  plt.plot(x,z1, label = \"$\\epsilon$ 0\")\n",
        "    l2, =  plt.plot(x,z2, label = \"$\\epsilon$ 0.1\")\n",
        "    l3, =  plt.plot(x,z3, label = \"$\\epsilon$ 0.01\")\n",
        "    l4, =  plt.plot(x,z4, label = \"$\\epsilon$ 0.1 - .0001\")\n",
        "   \n",
        "    plt.legend(handles=[l1,l2,l3, l4], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# plot for question2\n",
        "def plot2(number_of_bandits, number_of_steps,number_of_arms):\n",
        "    x = np.arange(number_of_steps)\n",
        "    y1, z1,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,2,temperature = .005)\n",
        "    y2, z2,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,2,temperature = .01)\n",
        "    y3, z3,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms, 2,temperature = .05)\n",
        "    y4, z4,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,2,temperature = .1)\n",
        "    y5, z5,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms, 2,temperature = .3)\n",
        "    y6, z6,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms, 2,temperature = .5)\n",
        "    y7, z7,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms, 2,temperature = 100)\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.title(\"Average performance of softmax action-value methods on the 10-armed testbed\",  fontsize=20)\n",
        "    plt.ylabel(\"Average reward\",  fontsize=20)\n",
        "    plt.xlabel(\"Steps\" , fontsize=20)\n",
        "    l1,=  plt.plot(x,y1, label = \"temperature = .005\")\n",
        "    l2, =  plt.plot(x,y2, label = \"temperature = .01\")\n",
        "    l3, =  plt.plot(x,y3, label = \"temperature = .05\")\n",
        "    l4, =  plt.plot(x,y4, label = \" temperature = .1\")\n",
        "    l5, =  plt.plot(x,y5, label = \"temperature = .3\")\n",
        "    l6, =  plt.plot(x,y6, label = \"temperature = .5\")\n",
        "    l7, =  plt.plot(x,y7, label = \"temperature = 100\")\n",
        "    \n",
        "    plt.legend(handles=[l1,l2,l3, l4,l5,l6, l7], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.ylabel(\"% Optimal action\",  fontsize=20)\n",
        "    plt.xlabel(\"Steps\",  fontsize=20)\n",
        "    l1,=  plt.plot(x,z1, label = \"temperature = .005\")\n",
        "    l2, =  plt.plot(x,z2, label = \"temperature = .01\")\n",
        "    l3, =  plt.plot(x,z3, label = \"temperature = .05\")\n",
        "    l4, =  plt.plot(x,z4, label = \" temperature = .1\")\n",
        "    l5, =  plt.plot(x,z5, label = \"temperature = .3\")\n",
        "    l6, =  plt.plot(x,z6, label = \"temperature = .5\")\n",
        "    l7, =  plt.plot(x,z7, label = \"temperature = 100\")\n",
        "   \n",
        "    plt.legend(handles=[l1,l2,l3, l4, l5,l6, l7], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    \n",
        "# plot for question 3\n",
        "def plot3(number_of_bandits,number_of_steps,number_of_arms):\n",
        "    x = np.arange(number_of_steps)\n",
        "    y1, z1,_,_ = generate_average_run(number_of_bandits, number_of_steps, number_of_arms,1,.1)\n",
        "    y2, z2,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,2,temperature = .3)\n",
        "    y3, z3,_,_ = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,3,c = 2)\n",
        "    # _,_,y4, z4 = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,4,epsilon = .99, delta = .99)\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.title(\"Comparison of performance of all four action-value methods on the 10-armed testbed\", fontsize=20)\n",
        "    plt.ylabel(\"Average reward\", fontsize=20)\n",
        "    plt.xlabel(\"Steps\", fontsize=20)\n",
        "    l1,=  plt.plot(x,y1, label = \" Epsilon Greedy $\\epsilon$ 0.1\")\n",
        "    l2, =  plt.plot(x,y2, label = \" Softmax temperature .3\")\n",
        "    l3, =  plt.plot(x,y3, label = \" UCB  c = 2\")\n",
        "    # l4, =  plt.plot(x,y4, label = \" MEDIAN \\epsilon = .99 \\delta = .99\")\n",
        "    \n",
        "    plt.legend(handles=[l1,l2,l3], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.ylabel(\"% Optimal action\", fontsize=20)\n",
        "    plt.xlabel(\"Steps\", fontsize=20)\n",
        "    l1,=  plt.plot(x,z1, label = \" Epsilon Greedy $\\epsilon$ 0.1\")\n",
        "    l2, =  plt.plot(x,z2, label = \" Softmax temperature = .3\")\n",
        "    l3, =  plt.plot(x,z3, label = \" UCB  c = 2\")\n",
        "    # l4, =  plt.plot(x,z4, label = \" MEDIAN \\epsilon = .99 \\delta = .99\")\n",
        "   \n",
        "    plt.legend(handles=[l1,l2,l3], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "####plot for question 4\n",
        "\n",
        "def plot4(number_of_bandits, number_of_steps,number_of_arms):\n",
        "    x = [.05, .08, .1, .3, .5]\n",
        "    # x = [.95, .94, .93,.92, .91]\n",
        "    y =[]\n",
        "    z = []\n",
        "\n",
        "    for i in range(5):\n",
        "        _,_,y1, z1 = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,4,epsilon = x[i], delta = .05)\n",
        "        print(y1,z1)\n",
        "        y.append(y1)\n",
        "        z.append(z1)\n",
        "\n",
        "    \n",
        "  \n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Average performance of Median action-value methods on the 10-armed testbed for different values of epsilon for a given delta = .05\",  fontsize=20)\n",
        "    plt.ylabel(\"Total number of samples\",  fontsize=20)\n",
        "    plt.xlabel(\"Epsilon\" , fontsize=20)\n",
        "    plt.plot(x,y)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.ylabel(\"% Optimal action retained\",  fontsize=20)\n",
        "    plt.xlabel(\"Epsilon\",  fontsize=20)\n",
        "    plt.plot(x,z)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(x,y,z)\n",
        " \n",
        "def plot5(number_of_bandits, number_of_steps,number_of_arms):\n",
        "    a1,b1,y1, z1 = generate_average_run(number_of_bandits, number_of_steps,number_of_arms,4,epsilon = .7, delta = .05)\n",
        "  \n",
        "   \n",
        "    \n",
        "    # print(y1)\n",
        "    # print(\"shape\",np.array(a1).shape,np.array(b1).shape)\n",
        "    qui = np.min([y1])\n",
        "    x = np.arange(qui)\n",
        "    \n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Average performance of Median Elimination  action-value methods on the 10-armed testbed\", fontsize=20)\n",
        "    plt.ylabel(\"Average reward\", fontsize=20)\n",
        "    plt.xlabel(\"Steps\", fontsize=20)\n",
        "    l1,=  plt.plot(x,a1[:qui], label = \" epsilon = .9, delta = .1\")\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    plt.legend(handles=[l1], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.ylabel(\"% Optimal action\", fontsize=20)\n",
        "    plt.xlabel(\"Steps\", fontsize=20)\n",
        "    l1,=  plt.plot(x,b1[:qui], label = \" epsilon = .9, delta = .1\")\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    plt.legend(handles=[l1], prop={'size': 18})\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    \n",
        "   \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI7oBUk_hI_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot5(2000,1000,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "307MDGm_D3oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot1(2000,10000, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccWZ94-zli8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot2(2000, 1000, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V92p9-Wqbmva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot3(2000, 3226,10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}